idx <- sample(seq_len(nrow(df)), size = size, replace = FALSE)
return(list(df[idx, ], df[-idx, ]))
}
rsf_model <- function (df) {
library(randomForestSRC)
library(survival)
model <- rfsrc(Surv(YearsAtCompany, Attrition) ~ ., data = df, ntree = 100)
return(model)
}
rsf_top_important_var <- function (df, num = 10) {
# Take variables with distinctively higher importance.
# By manual check, 10 seems to be enough.
rsfm <- rsf_model(df)
imp_score <- predict(rsfm, importance = TRUE)$importance
sorted_imp_score <- imp_score[order(imp_score, decreasing = TRUE)]
top_var <- sorted_imp_score[1:num]
return(top_var)
}
rsf_top_risk_individual <- function (train, test, proportion = 0.2) {
# Take some people so that the true capture is 50%.
# Top 20% seem to be enough
rsfm <- rsf_model(train)
hazard_score <- predict(rsfm, test, importance = TRUE)$predicted
sorted_test <- test[order(hazard_score, decreasing = TRUE), ]
size <- round(proportion * nrow(test))
top_risk_indv <- sorted_test[1:size, ]
return(top_risk_indv)
}
rsf_performance_score <- function(train, test) {
# How accurate are we doing
top_risk_indv <- rsf_top_risk_individual(train, test)
true_capture_rate <- sum(top_risk_indv$Attrition == TRUE)/sum(test$Attrition == TRUE)
false_avoidance_rate <- 1 - sum(top_risk_indv$Attrition == FALSE)/sum(test$Attrition == FALSE)
return(c(true_capture_rate, false_avoidance_rate))
}
cross_val <- function (k = 10) {
true_capture_rate <- numeric(k)
false_avoidance_rate <- numeric(k)
# rank variables
for (i in 1:k) {
tg <- train_test_generate(hr, i)
train_hr <- tg[[1]]
test_hr <- tg[[2]]
pfm_score <- rsf_performance_score(train_hr, test_hr)
true_capture_rate[i] <- pfm_score[1]
false_avoidance_rate[i] <- pfm_score[2]
}
sprintf("Our random survival forest model averagely have %.2f true capture rate (sd: %.2f) and %.2f false capture rate (sd: %.2f)",
mean(true_capture_rate), sd(true_capture_rate),
mean(false_avoidance_rate), sd(false_avoidance_rate))
}
# General process
cross_val()
tg <- train_test_generate(hr)
train_hr <- tg[[1]]
test_hr <- tg[[2]]
rsf_top_important_var(train_hr)
ggplot(data = melted_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(col = colorRampPalette(c("lightblue", "darkblue"))
ggplot(data = melted_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
ggplot(data = melted_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(col = colorRampPalette(c("lightblue", "darkblue")))
library(ggplot2)
cor_matrix <- cor(hr[, !(names(hr) %in% cat_cols)])
library(reshape2)
melted_cor_matrix <- melt(cor_matrix)
ggplot(data = melted_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(col = colorRampPalette(c("lightblue", "darkblue")))
ggplot(data = melted_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(col = colorRampPalette(c("lightblue", "darkblue"))(20))
ggplot(data = melted_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient(low = "lightblue", high = "darkblue", guide = "colorbar")
cross_val <- function (k = 10) {
true_capture_rate <- numeric(k)
false_avoidance_rate <- numeric(k)
# Rank variables
for (i in 1:k) {
tg <- train_test_generate(hr, i)
train_hr <- tg[[1]]
test_hr <- tg[[2]]
pfm_score <- rsf_performance_score(train_hr, test_hr)
true_capture_rate[i] <- pfm_score[1]
false_avoidance_rate[i] <- pfm_score[2]
}
sprintf("Our random survival forest model averagely have %.2f true capture rate (sd: %.2f) and %.2f false capture rate (sd: %.2f)",
mean(true_capture_rate), sd(true_capture_rate),
mean(false_avoidance_rate), sd(false_avoidance_rate))
# Determine top important variables
tg <- train_test_generate(hr)
train_hr <- tg[[1]]
test_hr <- tg[[2]]
rsf_top_important_var(train_hr)
}
# First iteration
cross_val()
remove_cols <- function(df, cols) df[, !(names(df) %in% cols)]
hr <- remove_cols(hr, c("EmployeeNumber"))
single_value_cols <- names(hr)[sapply(hr, function (col) length(unique(col)) == 1)]
hr <- remove_cols(hr, single_value_cols)
predict(rsf_model, test, importance = TRUE)
predict(rsf_model, test_hr, importance = TRUE)
predict(rsfm, test, importance = TRUE)
# Import & clean
rm(list = ls())
setwd("Downloads/shuuheialb.github.io/projects/employee-turnover")
hr <- read.csv("emp_attrition.csv")
remove_cols <- function(df, cols) df[, !(names(df) %in% cols)]
hr <- remove_cols(hr, c("EmployeeNumber"))
single_value_cols <- names(hr)[sapply(hr, function (col) length(unique(col)) == 1)]
hr <- remove_cols(hr, single_value_cols)
cat_cols <- c("Attrition", "BusinessTravel", "Department", "EducationField", "Gender", "JobRole", "MaritalStatus", "OverTime")
hr[cat_cols] <- lapply(hr[cat_cols], factor)
summary(hr)
hr$Attrition <- ifelse(hr$Attrition == "Yes", TRUE, FALSE)
# Cross-validation functions
train_test_generate <- function (df, seed = 123, proportion = 0.7) {
set.seed(seed)
size <- round(proportion * nrow(df))
idx <- sample(seq_len(nrow(df)), size = size, replace = FALSE)
return(list(df[idx, ], df[-idx, ]))
}
rsf_model <- function (df) {
library(randomForestSRC)
library(survival)
model <- rfsrc(Surv(YearsAtCompany, Attrition) ~ ., data = df, ntree = 100)
return(model)
}
rsf_propensity_score <- function (train, test) {
# Take some people so that the true capture is 50%.
# Top 20% seem to be enough
rsfm <- rsf_model(train)
hazard_score <- predict(rsfm, test, importance = TRUE)$predicted
sorted_test <- test[order(hazard_score, decreasing = TRUE), ]
size <- round(proportion * nrow(test))
top_risk_indv <- sorted_test[1:size, ]
return(top_risk_indv)
}
rsf_top_important_var <- function (df, num = 10) {
# Take variables with distinctively higher importance.
# By manual check, 10 seems to be enough.
rsfm <- rsf_model(df)
imp_score <- predict(rsfm, importance = TRUE)$importance
sorted_imp_score <- imp_score[order(imp_score, decreasing = TRUE)]
top_var <- sorted_imp_score[1:num]
return(top_var)
}
rsf_top_risk_individual <- function (train, test, proportion = 0.2) {
# Take some people so that the true capture is 50%.
# Top 20% seem to be enough
rsfm <- rsf_model(train)
hazard_score <- predict(rsfm, test, importance = TRUE)$predicted
sorted_test <- test[order(hazard_score, decreasing = TRUE), ]
size <- round(proportion * nrow(test))
top_risk_indv <- sorted_test[1:size, ]
return(top_risk_indv)
}
rsf_performance_score <- function(train, test) {
# How accurate are we doing
top_risk_indv <- rsf_top_risk_individual(train, test)
true_capture_rate <- sum(top_risk_indv$Attrition == TRUE)/sum(test$Attrition == TRUE)
false_avoidance_rate <- 1 - sum(top_risk_indv$Attrition == FALSE)/sum(test$Attrition == FALSE)
return(c(true_capture_rate, false_avoidance_rate))
}
cross_val <- function (k = 10) {
true_capture_rate <- numeric(k)
false_avoidance_rate <- numeric(k)
# Rank variables
for (i in 1:k) {
tg <- train_test_generate(hr, i)
train_hr <- tg[[1]]
test_hr <- tg[[2]]
pfm_score <- rsf_performance_score(train_hr, test_hr)
true_capture_rate[i] <- pfm_score[1]
false_avoidance_rate[i] <- pfm_score[2]
}
sprintf("Our random survival forest model averagely have %.2f true capture rate (sd: %.2f) and %.2f false capture rate (sd: %.2f)",
mean(true_capture_rate), sd(true_capture_rate),
mean(false_avoidance_rate), sd(false_avoidance_rate))
# Determine top important variables
tg <- train_test_generate(hr)
train_hr <- tg[[1]]
test_hr <- tg[[2]]
print(rsf_top_important_var(train_hr))
}
# First iteration
cross_val()
predict(rsf_model(test_hr), test_hr, importance = TRUE)
predict(rsf_model(hr), hr, importance = TRUE)
x <- predict(rsf_model(hr), hr, importance = TRUE)
View(x)
tg <- train_test_generate(hr)
train_hr <- tg[[1]]
test_hr <- tg[[2]]
x <- predict(rsf_model(train_hr), test_hr, importance = TRUE)
su(x.yvar == test_hr$Attrition)
sum(x.yvar == test_hr$Attrition)
sum(x$yvar$Attrition == test_hr$Attrition)
x <- predict(rsf_model(train_hr), test_hr, times = 1)
x <- predict(rsf_model(train_hr), test_hr, times = c(0, 1, 2))
rsf_turnover_propensity_score <- function (train, test) {
rsfm <- rsf_model(train)
return(predict(rsfm, test)$chf
}
rsf_turnover_propensity_score <- function (train, test) {
rsfm <- rsf_model(train)
return(predict(rsfm, test))$chf
}
hr <- remove_cols(hr, c("JobLevel", "PerformanceRating", "YearsWithCurrManager", "YearsWithCurrManager", "YearsSinceLastPromotion"))
cross_val()
library(ggplot2)
cor_matrix <- cor(hr[, !(names(hr) %in% cat_cols)])
library(reshape2)
melted_cor_matrix <- melt(cor_matrix)
ggplot(data = melted_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient(low = "lightblue", high = "darkblue", guide = "colorbar")
hr <- remove_cols(hr, c("JobLevel", "PerformanceRating", "YearsInCurrentRole", "YearsWithCurrManager", "YearsSinceLastPromotion"))
cross_val()
library(ggplot2)
cor_matrix <- cor(hr[, !(names(hr) %in% cat_cols)])
library(reshape2)
melted_cor_matrix <- melt(cor_matrix)
ggplot(data = melted_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient(low = "lightblue", high = "darkblue", guide = "colorbar")
cross_val()
tg <- train_test_generate(hr)
train_hr <- tg[[1]]
test_hr <- tg[[2]]
print(rsf_top_important_var(train_hr))
cross_val <- function (k = 10) {
true_capture_rate <- numeric(k)
false_avoidance_rate <- numeric(k)
# Rank variables
for (i in 1:k) {
tg <- train_test_generate(hr, i)
train_hr <- tg[[1]]
test_hr <- tg[[2]]
pfm_score <- rsf_performance_score(train_hr, test_hr)
true_capture_rate[i] <- pfm_score[1]
false_avoidance_rate[i] <- pfm_score[2]
}
print(sprintf("Our random survival forest model averagely have %.2f true capture rate (sd: %.2f) and %.2f false capture rate (sd: %.2f)",
mean(true_capture_rate), sd(true_capture_rate),
mean(false_avoidance_rate), sd(false_avoidance_rate)))
# Determine top important variables
tg <- train_test_generate(hr)
train_hr <- tg[[1]]
test_hr <- tg[[2]]
print(rsf_top_important_var(train_hr))
}
# First iteration
cross_val()
plot(rsf_performance_score(test_hr))
cross_val <- function (k = 10) {
true_capture_rate <- numeric(k)
false_avoidance_rate <- numeric(k)
# Rank variables
for (i in 1:k) {
tg <- train_test_generate(hr, i)
train_hr <- tg[[1]]
test_hr <- tg[[2]]
pfm_score <- rsf_performance_score(train_hr, test_hr)
true_capture_rate[i] <- pfm_score[1]
false_avoidance_rate[i] <- pfm_score[2]
}
print(sprintf("Our random survival forest model averagely have %.2f true capture rate (sd: %.2f) and %.2f false capture rate (sd: %.2f)",
mean(true_capture_rate), sd(true_capture_rate),
mean(false_avoidance_rate), sd(false_avoidance_rate)))
# Determine top important variables
tg <- train_test_generate(hr)
train_hr <- tg[[1]]
test_hr <- tg[[2]]
print(rsf_top_important_var(train_hr))
plot(rsf_performance_score(test_hr))
}
# First iteration
cross_val()
cross_val <- function (k = 10) {
true_capture_rate <- numeric(k)
false_avoidance_rate <- numeric(k)
# Rank variables
for (i in 1:k) {
tg <- train_test_generate(hr, i)
train_hr <- tg[[1]]
test_hr <- tg[[2]]
pfm_score <- rsf_performance_score(train_hr, test_hr)
true_capture_rate[i] <- pfm_score[1]
false_avoidance_rate[i] <- pfm_score[2]
}
print(sprintf("Our random survival forest model averagely have %.2f true capture rate (sd: %.2f) and %.2f false capture rate (sd: %.2f)",
mean(true_capture_rate), sd(true_capture_rate),
mean(false_avoidance_rate), sd(false_avoidance_rate)))
# Determine top important variables
tg <- train_test_generate(hr)
train_hr <- tg[[1]]
test_hr <- tg[[2]]
print(rsf_top_important_var(train_hr))
plot(rsf_turnover_propensity_score(train_h, test_hr))
}
# First iteration
cross_val()
plot(rsf_turnover_propensity_score(train_hr, test_hr))
rsf_turnover_propensity_score(train_hr, test_hr)
x <- rsf_turnover_propensity_score(train_hr, test_hr)
rsf_turnover_propensity_score <- function (train, test) {
rsfm <- rsf_model(train)
return(predict(rsfm, test)$chf)
}
cross_val()
cross_val <- function (k = 10) {
true_capture_rate <- numeric(k)
false_avoidance_rate <- numeric(k)
# Rank variables
for (i in 1:k) {
tg <- train_test_generate(hr, i)
train_hr <- tg[[1]]
test_hr <- tg[[2]]
pfm_score <- rsf_performance_score(train_hr, test_hr)
true_capture_rate[i] <- pfm_score[1]
false_avoidance_rate[i] <- pfm_score[2]
}
print(sprintf("Our random survival forest model averagely have %.2f true capture rate (sd: %.2f) and %.2f false capture rate (sd: %.2f)",
mean(true_capture_rate), sd(true_capture_rate),
mean(false_avoidance_rate), sd(false_avoidance_rate)))
# Determine top important variables
tg <- train_test_generate(hr)
train_hr <- tg[[1]]
test_hr <- tg[[2]]
print(rsf_top_important_var(train_hr))
plot(rsf_turnover_propensity_score(train_hr, test_hr))
}
# First iteration
cross_val()
rsf_turnover_propensity_score(train_hr, test_hr)
predict(rsf_model(train_h), test_h,)
predict(rsf_model(train_h), test_hr)
predict(rsf_model(train_hh), test_hr)
predict(rsf_model(train_hr), test_hr)
predict(rsf_model(train_hr), test_hr)$pred
predict(rsf_model(train_hr), test_hr)$predict
predict(rsf_model(train_hr), test_hr)$predicted
predict(rsf_model(train_hr), test_hr$survival
predict(rsf_model(train_hr), test_hr$survival
predict(rsf_model(train_hr), test_hr)$survival
rsf_var_importance <- function (df) {
# Take variables with distinctively higher importance.
# By manual check, 10 seems to be enough.
rsfm <- rsf_model(df)
imp_score <- predict(rsfm, importance = TRUE)$importance
sorted_imp_score <- imp_score[order(imp_score, decreasing = TRUE)]
return(sorted_imp_score)
}
rsf_var_importance(train_hr)
predict(rsf_model(train_hr), test_hr$survival
)
predict(rsf_model(train_hr), test_hr)$survival
predict(rsf_model(hr), hr, oob = TRUE)
929/1470
y <- predict(rsf_model(hr), hr, oob = TRUE)
View(y)
install.packages("pec")
library(pec)
rsfm <- rsf_model(hr)
pred_error <- pec(rsfm, formula = Surv(time,status) ~ .,
data = hr,
exact = TRUE,
cens.mode = "marginal",
splitMethod = "none",
B = 0,
verbose = TRUE)
pred_error <- pec(rsfm, formula = Surv(YearsAtCompany, Attrition) ~ .,
data = hr,
exact = TRUE,
cens.mode = "marginal",
splitMethod = "none",
B = 0,
verbose = TRUE)
plot(pred_error,xlim=c(0,30))
set.seed(130971)
library(prodlim)
library(survival)
dat <- SimSurv(100)
# fit some candidate Cox models and compute the Kaplan-Meier estimate
Models <- list("Cox.X1"=coxph(Surv(time,status)~X1,data=dat,x=TRUE,y=TRUE),
"Cox.X2"=coxph(Surv(time,status)~X2,data=dat,x=TRUE,y=TRUE),
"Cox.X1.X2"=coxph(Surv(time,status)~X1+X2,data=dat,x=TRUE,y=TRUE))
# compute the apparent prediction error
PredError <- pec(object=Models,
formula=Surv(time,status)~X1+X2,
data=dat,
exact=TRUE,
cens.model="marginal",
splitMethod="none",
B=0,
verbose=TRUE)
print(PredError,times=seq(5,30,5))
summary(PredError)
plot(PredError,xlim=c(0,30))
pred_error <- pec(rsfm, formula = Surv(YearsAtCompany, Attrition) ~ .,
data = hr,
exact = TRUE,
cens.mode = "marginal",
splitMethod = "none",
B = 0)
plot(pred_error,xlim=c(0,30))
rsf_performance_score <- function(train, test) {
library(pec)
rsfm <- rsf_model(hr)
pred_error <- pec(rsfm, formula = Surv(YearsAtCompany, Attrition) ~ .,
data = hr,
exact = TRUE,
cens.mode = "marginal",
splitMethod = "none",
verbose = TRUE)
plot(pred_error,xlim=c(0,30))
}
pred_error <- pec(rsfm, formula = Surv(YearsAtCompany, Attrition) ~ .,
data = hr,
exact = TRUE,
cens.mode = "marginal",
splitMethod = "none",
verbose = TRUE)
plot(pred_error,xlim=c(0,30))
pred_error <- pec(rsfm, formula = Surv(YearsAtCompany, Attrition) ~ .,
data = hr,
cens.model = "marginal",
splitMethod = "none")
plot(pred_error,xlim=c(0,30))
rsfm <- rsf_model(hr)
pred_error <- pec(rsfm, formula = Surv(YearsAtCompany, Attrition) ~ .,
data = hr,
cens.model = "marginal",
splitMethod = "none")
plot(pred_error,xlim=c(0,30))
pred_error <- pec(rsfm, formula = Surv(YearsAtCompany, Attrition) ~ .,
data = hr,
splitMethod = "Boot632"
cens.model = "marginal")
pred_error <- pec(rsfm, formula = Surv(YearsAtCompany, Attrition) ~ .,
data = hr,
splitMethod = "Boot632",
cens.model = "marginal")
plot(pred_error,xlim=c(0,30))
# No need to cross validate the RSF, but maybe for backup
train_test_generate <- function (df, seed = 123, proportion = 0.7) {
set.seed(seed)
size <- round(proportion * nrow(df))
idx <- sample(seq_len(nrow(df)), size = size, replace = FALSE)
return(list(df[idx, ], df[-idx, ]))
}
hr <- read.csv("emp_attrition.csv")
remove_cols <- function(df, cols) df[, !(names(df) %in% cols)]
hr <- remove_cols(hr, c("EmployeeNumber"))
single_value_cols <- names(hr)[sapply(hr, function (col) length(unique(col)) == 1)]
hr <- remove_cols(hr, single_value_cols)
cat_cols <- c("Attrition", "BusinessTravel", "Department", "EducationField", "Gender", "JobRole", "MaritalStatus", "OverTime")
hr[cat_cols] <- lapply(hr[cat_cols], factor)
summary(hr)
hr$Attrition <- ifelse(hr$Attrition == "Yes", TRUE, FALSE)
# Model building
library(randomForestSRC)
library(survival)
library(pec, warn.conflicts = FALSE)
library(ggplot2)
library(reshape2)
# Model
rsf_model <- function (df) {
model <- rfsrc(Surv(YearsAtCompany, Attrition) ~ ., data = df, ntree = 100)
return(model)
}
# For tweaking model
rsf_pec <- function(df, model) {
pred_error <- pec(model, data = df, formula = Surv(YearsAtCompany, Attrition) ~ .,
splitMethod = "cv10", cens.model = "marginal")
return(pred_error)
}
rsf_var_importance <- function (df, model) {
importance <- predict(model, importance = TRUE)$importance
sorted_importance <- importance[order(importance, decreasing = TRUE)]
return(sorted_importance)
}
plot_correlation <- function (df, model) {
cor_matrix <- cor(df[, !(names(df) %in% cat_cols)]) # Warning: global cat_cols
melted_cor_matrix <- melt(cor_matrix)
ggplot(data = melted_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient(low = "lightblue", high = "darkblue", guide = "colorbar") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
}
# No need to cross validate the RSF, but maybe for backup
train_test_generate <- function (df, seed = 123, proportion = 0.7) {
set.seed(seed)
size <- round(proportion * nrow(df))
idx <- sample(seq_len(nrow(df)), size = size, replace = FALSE)
return(list(df[idx, ], df[-idx, ]))
}
# Result
rsf_turnover_probability <- function (df, model) {
return(predict(model, df)$chf)
}
# First iteration
model <- rsf_model(hr)
plot(rsf_pec(hr, model), xlim = c(0,30))
print(rsf_var_importance(hr, model))
plot_correlation(hr, model)
install.packages("dplyr")
install.packages("ggcorrplot")
install.packages("ggcorrplot")
install.packages("ggcorrplot")
install.packages("ggcorrplot")
