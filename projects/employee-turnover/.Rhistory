# b.
sum(postSamples < 0.4)/length(postSamples)
pbeta(0.4, a0+s, b0+n-s)
15/22
mean(c(1,2))
mean(c(1,2,3))
apply(c(1, 2), fun = function(x) x+1)
apply(c(1, 2), FUN <- function(variables) {
} = function(x) x+1)
apply(c(1, 2), FUN <- function(x) x+1)
apply(c(1, 2), FUN <- function(x) {x+1})
apply(c(1, 2), 1, function(x) {x+1})
sapply(c(1, 2), function(x) {x+1})
sapply(c(1, 2), function(x) x+1)
hist(sapply(postSamples, function(x) log(x/(1-x))))
logOdds <- sapply(postSamples, function(x) log(x/(1-x)))
hist(logOdds)
c(1.2)/c(2,3)
mapply(function(x, y) x/y, c(1.2), c(2,3))
c(1,2)/c(2,3)
library(poolr)
install.packages("poolr")
.libPaths()
remove.packages("poolr")
install.packages("geoR")
mean(postSamples) # actual mean: (a0+s-1)/(a0+b0+n-2) = 15/22
sd(postSamples)/sqrt(k)
a0 = 2; b0 = 2; s = 14; n = 20; k = 1000
postSamples <- rbeta(k, a0+s, b0+n-s)
mean(postSamples) # actual mean: (a0+s)/(a0+b0+n) = 16/24
sd(postSamples)/sqrt(k)
remove.packages("poolr")
library(LaplacesDemon)
install.packages(LaplacesDemon)
install.packages("LaplacesDemon")
library(LaplacesDemon)
obs <- c(27, 37, 44, 52, 60, 71, 83, 100, 133, 150)
mu = 4.5; n = 10; k = 10000;
sim <- rinvchisq(k, n, mu)
hist(sim)
sim <- rinvchisq(k, n, (log(obs) - mu)^2/n)
hist(sim)
sim <- rinvchisq(k, n, sqrt((log(obs) - mu)^2/n))
hist(sim)
dnorm(0)
pnorm(0)
dnorm(0)
dga,,a(0)
dgamma(0)
dunif(0)
dunif(-1)
dunif(1)
pnorm(c(0, 0))
Gs <- 2*pnorm(sigmaSqs/sqrt(2)) -1
hist(Gs)
library(LaplacesDemon)
obs <- c(27, 37, 44, 52, 60, 71, 83, 100, 133, 150)
mu = 4.5; n = 10; k = 10000;
sigmaSqs <- rinvchisq(k, n, sqrt((log(obs) - mu)^2/n))
# c.
Gs <- 2*pnorm(sigmaSqs/sqrt(2)) -1
hist(Gs)
library(LaplacesDemon)
obs <- c(27, 37, 44, 52, 60, 71, 83, 100, 133, 150)
mu = 4.5; n = 10; k = 10000;
sigmaSqs <- rinvchisq(k, n, sqrt((log(obs) - mu)^2/n))
# c.
G <- 2*pnorm(sigmaSqs/sqrt(2)) -1
hist(G)
G <- 2*pnorm(sigmaSqs/sqrt(2)) -1
hist(G)
credibleIntv <- function(a0) pgamma(5, a0, 4*a0) - pgamma(3, a0, 4*a0)
a0 <- seq(0, 5, 0.1)
probLambdaBetween3And5 <- sapply(a0, credibleIntv)
plot(a0, probLambdaBetween3And5)
credibleIntv <- function(a0) pgamma(5, a0, 4*a0) - pgamma(3, a0, 4*a0)
a0 <- seq(0, 1, 0.1)
probLambdaBetween3And5 <- sapply(a0, credibleIntv)
plot(a0, probLambdaBetween3And5)
credibleIntv <- function(a0) pgamma(5, a0, 4*a0) - pgamma(3, a0, 4*a0)
a0 <- seq(0, 1, 0.1)
probLambdaBetween3And5 <- sapply(a0, credibleIntv)
plot(a0, probLambdaBetween3And5)
credibleIntv <- function(a0) pgamma(5, a0, 4*a0) - pgamma(3, a0, 4*a0)
a0 <- seq(0, 0.1, 0.01)
probLambdaBetween3And5 <- sapply(a0, credibleIntv)
plot(a0, probLambdaBetween3And5)
credibleIntv <- function(a0) pgamma(5, a0, a0/4) - pgamma(3, a0, a0/4)
a0 <- seq(0, 1, 0.1)
probLambdaBetween3And5 <- sapply(a0, credibleIntv)
plot(a0, probLambdaBetween3And5)
credibleIntv <- function(a0) pgamma(5, a0, a0/4) - pgamma(3, a0, a0/4)
a0 <- seq(0, 5, 0.1)
probLambdaBetween3And5 <- sapply(a0, credibleIntv)
plot(a0, probLambdaBetween3And5)
credibleIntv <- function(a0) pgamma(5, a0, a0/4) - pgamma(3, a0, a0/4)
a0 <- seq(5, 6, 0.1)
probLambdaBetween3And5 <- sapply(a0, credibleIntv)
plot(a0, probLambdaBetween3And5)
credibleIntv <- function(a0) pgamma(5, a0, a0/4) - pgamma(3, a0, a0/4)
a0 <- seq(6, 8, 0.1)
probLambdaBetween3And5 <- sapply(a0, credibleIntv)
plot(a0, probLambdaBetween3And5)
credibleIntv <- function(a0) pgamma(5, a0, a0/4) - pgamma(3, a0, a0/4)
a0 <- seq(7, 7.5, 0.01)
probLambdaBetween3And5 <- sapply(a0, credibleIntv)
plot(a0, probLambdaBetween3And5)
credibleIntv <- function(a0) pgamma(5, a0, a0/4) - pgamma(3, a0, a0/4)
a0 <- seq(7, 7.5, 0.1)
probLambdaBetween3And5 <- sapply(a0, credibleIntv)
plot(a0, probLambdaBetween3And5)
# Approx a0 = 7.2, b0 = 1.8
a0 = 7.2; b0 = 1.8
ys <- c(2, 5, 3, 5, 3, 1)
ns <- c(120342, 235967, 243745, 197452, 276935, 157222)
am <- a0 + sum(ys)
bm <- b0 + sum(ns)/100000
lambda <- seq(-3, 3, 0.1)
plot(lambda, dgamma(lambda, a0, b0))
am <- a0 + sum(ys)
bm <- b0 + sum(ns)/100000
lambda <- seq(0, 5, 0.1)
plot(lambda, dgamma(lambda, a0, b0))
dgamma(lambda, am, bm)
lambda <- seq(0, 10, 0.1)
plot(lambda, dgamma(lambda, a0, b0))
dgamma(lambda, am, bm)
plot(lambda)
lines(dgamma(lambda, a0, b0))
help("plot")
plot(lambda, dgamma(lambda, a0, b0), type="l")
lines(lambda, dgamma(lambda, am, bm)
)
plot(lambda, dgamma(lambda, a0, b0), type="l", ylim = c(0, 1))
lines(lambda, dgamma(lambda, am, bm))
plot(lambda, dgamma(lambda, a0, b0), type="l", ylim = c(0, 2))
lines(lambda, dgamma(lambda, am, bm))
plot(lambda, dgamma(lambda, a0, b0), type="l", ylim = c(0, 1.5))
lines(lambda, dgamma(lambda, am, bm))
plot(lambda, dgamma(lambda, a0, b0), type="l", ylim = c(0, 1.2))
lines(lambda, dgamma(lambda, am, bm))
credibleIntv <- function(a0) pgamma(5, a0, a0/4) - pgamma(3, a0, a0/4)
a0 <- seq(7, 7.5, 0.1)
probLambdaBetween3And5 <- sapply(a0, credibleIntv)
plot(a0, probLambdaBetween3And5)
p <- function(a0) pgamma(5, a0, a0/4) - pgamma(3, a0, a0/4)
a0 <- seq(7, 7.5, 0.1)
probLambdaBetween3And5 <- sapply(a0, p)
plot(a0, probLambdaBetween3And5)
p <- function(a, b = a/4) pgamma(5, a, b) - pgamma(3, a, b)
a0 <- seq(7, 7.5, 0.1)
probLambdaBetween3And5 <- sapply(a0, p)
plot(a0, probLambdaBetween3And5)
p(am, bm)
library(haven)
X1ResearchProjectData <- read_sav("Downloads/1ResearchProjectData.sav")
View(X1ResearchProjectData)
install.packages(c('pbdZMQ', 'repr', 'devtools'))
install.packages(c("pbdZMQ", "repr", "devtools"))
devtools::install_github('IRkernel/IRdisplay')
devtools::install_github('IRkernel/IRkernel')
IRkernel::installspec()
install.packages('devtool')
install.packages('devtools')
install.packages(c('libfreetype6-dev','libpng-dev', 'libtiff5-dev', 'libjpeg-dev'))
install.packages(ggscatter)
install.packages("ggscatter"
)
install.packages("car")
install.packages("car", dependencies = TRUE)
install.packages("effects", dependencies = TRUE)
install.packages("car",dependencies=TRUE)
install.packages("car",repos = c("http://rstudio.org/_packages",
"http://cran.rstudio.com"))
install.packages(c("car", "pbkrtest", "lme4"),repos = c("http://rstudio.org/_packages",
"http://cran.rstudio.com"))
install.packages(c("car", "pbkrtest", "lme4"),repos = c("http://rstudio.org/_packages",
"http://cran.rstudio.com"), dependencies = TRUE)
install.packages(c("car"),repos = c("http://rstudio.org/_packages",
"http://cran.rstudio.com"), dependencies = TRUE)
install.packages(c("car"),repos = c("http://rstudio.org/_packages",
"http://cran.rstudio.com"), dependencies = TRUE)
install.packages(c("DescTools"),repos = c("http://rstudio.org/_packages",
"http://cran.rstudio.com"), dependencies = TRUE)
install.packages(c("ggfortify"),repos = c("http://rstudio.org/_packages",
"http://cran.rstudio.com"), dependencies = TRUE)
install.packages(chron)
install.packages("chron")
data <- read.csv("Hospital ER.csv")
ls
data <- read.csv("Hospital ER.csv")
pwd
strsplit(c("a b", "c d"
), split = " ")
strsplit(c("a b", "c d"), split = " ")[, 1]
install.packages("DataExplorer")
install.packages("zoo")
install.packages("sure")
install.packages("gridExtra")
sample(1:20, 1)
10^5
sample(1:20)
runif()
cols(x)
colnames(x)
colnames(hr)
plot_correlation(hr, model)
rm(list = ls())
setwd("Downloads/shuuheialb.github.io/projects/employee-turnover")
hr <- read.csv("emp_attrition.csv")
remove_cols <- function(df, cols) df[, !(names(df) %in% cols)]
hr <- remove_cols(hr, c("EmployeeNumber"))
single_value_cols <- names(hr)[sapply(hr, function (col) length(unique(col)) == 1)]
hr <- remove_cols(hr, single_value_cols)
cat_cols <- c("Attrition", "BusinessTravel", "Department", "EducationField", "Gender", "JobRole", "MaritalStatus", "OverTime")
hr[cat_cols] <- lapply(hr[cat_cols], factor)
summary(hr)
hr$Attrition <- ifelse(hr$Attrition == "Yes", TRUE, FALSE)
# Model building
library(randomForestSRC)
library(survival)
library(pec, warn.conflicts = FALSE)
library(ggplot2)
library(reshape2)
# Model
rsf_model <- function (df) {
model <- rfsrc(Surv(YearsAtCompany, Attrition) ~ ., data = df, ntree = 100)
return(model)
}
# For tweaking model
rsf_pec <- function(df, model) {
pred_error <- pec(model, data = df, formula = Surv(YearsAtCompany, Attrition) ~ .,
splitMethod = "cv10", cens.model = "marginal")
return(pred_error)
}
rsf_var_importance <- function (df, model) {
importance <- predict(model, importance = TRUE)$importance
sorted_importance <- importance[order(importance, decreasing = TRUE)]
return(sorted_importance)
}
plot_correlation <- function (df, model) {
cor_matrix <- cor(df[, !(names(df) %in% cat_cols)]) # Warning: global cat_cols
melted_cor_matrix <- melt(cor_matrix)
ggplot(data = melted_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient(low = "lightblue", high = "darkblue", guide = "colorbar") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
}
# No need to cross validate the RSF, but maybe for backup
train_test_generate <- function (df, seed = 123, proportion = 0.7) {
set.seed(seed)
size <- round(proportion * nrow(df))
idx <- sample(seq_len(nrow(df)), size = size, replace = FALSE)
return(list(df[idx, ], df[-idx, ]))
}
# Result
rsf_turnover_probability <- function (df, model) {
return(predict(model, df)$chf)
}
# First iteration
model <- rsf_model(hr)
plot(rsf_pec(hr, model), xlim = c(0,30))
print(rsf_var_importance(hr, model))
plot_correlation(hr, model)
colnames(hr)
numeric(10)
importance_df <- numeric(ncol(df))
importance_df <- numeric(ncol(hr))
names(importance_df) <- names(hrh)
importance_df <- numeric(ncol(hr))
names(importance_df) <- names(hr)
print(importance_df)
hr[, !(names(hr) %in% c(["Age"]))]
hr[, !(names(hr) %in% c("Age"))]
importance_df[, !(names(importance_df) %in% c("Age"))]
names(importance_df)
names(importance_df) %in% c("Age")
importance_df[, !(names(importance_df) %in% c("Age"))]
!(names(importance_df) %in% c("Age"))
numeric(10, 1-)
numeric(10, 10)
install.packages("viridis")
rsf_top_risk_individual(hr, model_v2)
# Import & clean
rm(list = ls())
setwd("Downloads/shuuheialb.github.io/projects/employee-turnover")
hr <- read.csv("emp_attrition.csv")
remove_cols <- function(df, cols) df[, !(names(df) %in% cols)]
hr <- remove_cols(hr, c("EmployeeNumber"))
single_value_cols <- names(hr)[sapply(hr, function (col) length(unique(col)) == 1)]
hr <- remove_cols(hr, single_value_cols)
cat_cols <- c("Attrition", "BusinessTravel", "Department", "EducationField", "Gender", "JobRole", "MaritalStatus", "OverTime")
hr[cat_cols] <- lapply(hr[cat_cols], factor)
summary(hr)
hr$Attrition <- ifelse(hr$Attrition == "Yes", TRUE, FALSE)
library(randomForestSRC)
library(survival)
library(pec, warn.conflicts = FALSE)
library(ggplot2)
library(reshape2)
library(viridis)
# Base model
rsf_model <- function (df) {
model <- rfsrc(Surv(YearsAtCompany, Attrition) ~ ., data = df, ntree = 100)
return(model)
}
# Accuracy plot
plot_pec <- function(df, model) {
pred_error <- pec(model, data = df, formula = Surv(YearsAtCompany, Attrition) ~ .,
splitMethod = "none", cens.model = "marginal")
plot(pred_error, xlim = c(0, 30), )
title("RSF Model Prediction Error Curve")
}
# Feature selection functions
# 1. Importance function
rsf_importance <- function (df, model, sort = TRUE) {
importance <- predict(model, importance = TRUE)$importance
if (sort) {
importance <- importance[order(importance, decreasing = TRUE)]
}
return(importance)
}
# 2. Averaged importance rank
train_test_generate <- function (df, proportion = 0.7) {
size <- round(proportion * nrow(df))
idx <- sample(seq_len(nrow(df)), size = size, replace = FALSE)
return(list("train" = df[idx, ], "test" = df[-idx, ]))
}
k_fold_cross_val <- function (df, k = 10) {
for (fold in 1:k) {
separate <- train_test_generate(df)
train <- separate$train
test <- separate$test
model <- rsf_model(train)
if (!(exists("importance_tot"))) {
importance_tot <- rsf_importance(test, model, FALSE)
} else {
importance_tot <- importance_tot + rsf_importance(test, model, FALSE)
}
}
print("Average variable importance:")
print(importance_tot[order(importance_tot, decreasing = TRUE)]/length(importance_tot))
}
# 3. Correlation
plot_correlation <- function (df, model) {
cor_matrix <- cor(df[, !(names(df) %in% cat_cols)])
melted_cor_matrix <- melt(cor_matrix)
melted_cor_matrix$value <- abs(melted_cor_matrix$value)
ggplot(data = melted_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() + scale_fill_viridis() +
xlab("") + ylab("") + ggtitle("Correlation Map") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
plot.title = element_text(hjust = 0.5))
}
# First iteration
#model <- rsf_model(hr)
#plot_pec(hr, model)
#k_fold_cross_val(hr)
#plot_correlation(hr, model)
# Second iteration
selected_features <- hr[, c("Attrition", "YearsAtCompany", "Age", "MonthlyIncome", "OverTime", "NumCompaniesWorked",
"StockOptionLevel", "JobRole")]
k_fold_cross_val(selected_features)
model_v2 <- rsf_model(selected_features)
plot_pec(selected_features, model_v2)
# Prediction
rsf_turnover_probability <- function (df, model) {
return(predict(model, df)$chf)
}
rsf_top_risk_individual <- function (df, model, limit = 100) {
df$HazardScore <- predict(model, df)$predict
print(df$HazardScore)
sorted_df <- df[order(df$HazardScore, decreasing = TRUE), ]
return(sorted_df[1:limit, ])
}
for (i in 1:5) {
hr[, paste0("AttritionProb_Year", i)] <- rsf_turnover_probability(hr, model_v2)[, i+1]
}
hr
rsf_top_risk_individual(hr, model_v2)
x <- predict(model_v2, hr)
View(x)
rsf_turnover_probability <- function (df, model) {
return(predict(model, df)$chf)
}
rsf_high_risk_indiv_idx <- function (df, model, limit = 100) {
df$HazardScore <- predict(model, df)$predicted
return(order(df$HazardScore, decreasing = TRUE)[1:limit])
}
for (i in 1:5) {
hr[, paste0("AttritionProb_Year", i)] <- rsf_turnover_probability(hr, model_v2)[, i+1]
}
hriidx <- rsf_high_risk_indiv_idx(hr, model_v2)
hr_emp_ids
rm(list = ls())
setwd("Downloads/shuuheialb.github.io/projects/employee-turnover")
hr <- read.csv("emp_attrition.csv")
remove_cols <- function(df, cols) df[, !(names(df) %in% cols)]
hr_emp_ids <- hr["EmployeeNumber"] # Save for backup
hr <- remove_cols(hr, c("EmployeeNumber"))
single_value_cols <- names(hr)[sapply(hr, function (col) length(unique(col)) == 1)]
hr <- remove_cols(hr, single_value_cols)
cat_cols <- c("Attrition", "BusinessTravel", "Department", "EducationField", "Gender", "JobRole", "MaritalStatus", "OverTime")
hr[cat_cols] <- lapply(hr[cat_cols], factor)
summary(hr)
hr$Attrition <- ifelse(hr$Attrition == "Yes", TRUE, FALSE)
library(randomForestSRC)
library(survival)
library(pec, warn.conflicts = FALSE)
library(ggplot2)
library(reshape2)
library(viridis)
# Base model
rsf_model <- function (df) {
model <- rfsrc(Surv(YearsAtCompany, Attrition) ~ ., data = df, ntree = 100)
return(model)
}
# Accuracy plot
plot_pec <- function(df, model) {
pred_error <- pec(model, data = df, formula = Surv(YearsAtCompany, Attrition) ~ .,
splitMethod = "none", cens.model = "marginal")
plot(pred_error, xlim = c(0, 30), )
title("RSF Model Prediction Error Curve")
}
# Feature selection functions
# 1. Importance function
rsf_importance <- function (df, model, sort = TRUE) {
importance <- predict(model, df, importance = TRUE)$importance
if (sort) {
importance <- importance[order(importance, decreasing = TRUE)]
}
return(importance)
}
# 2. Averaged importance rank
train_test_generate <- function (df, proportion = 0.7) {
size <- round(proportion * nrow(df))
idx <- sample(seq_len(nrow(df)), size = size, replace = FALSE)
return(list("train" = df[idx, ], "test" = df[-idx, ]))
}
k_fold_cross_val <- function (df, k = 10) {
for (fold in 1:k) {
separate <- train_test_generate(df)
train <- separate$train
test <- separate$test
model <- rsf_model(train)
if (!(exists("importance_tot"))) {
importance_tot <- rsf_importance(test, model, FALSE)
} else {
importance_tot <- importance_tot + rsf_importance(test, model, FALSE)
}
}
print("Average variable importance:")
print(importance_tot[order(importance_tot, decreasing = TRUE)]/length(importance_tot))
}
# 3. Correlation
plot_correlation <- function (df, model) {
cor_matrix <- cor(df[, !(names(df) %in% cat_cols)])
melted_cor_matrix <- melt(cor_matrix)
melted_cor_matrix$value <- abs(melted_cor_matrix$value)
ggplot(data = melted_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() + scale_fill_viridis() +
xlab("") + ylab("") + ggtitle("Correlation Map") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
plot.title = element_text(hjust = 0.5))
}
# First iteration
#model <- rsf_model(hr)
#plot_pec(hr, model)
#k_fold_cross_val(hr)
#plot_correlation(hr, model)
# Second iteration
selected_features <- hr[, c("Attrition", "YearsAtCompany", "Age", "MonthlyIncome", "OverTime", "NumCompaniesWorked",
"StockOptionLevel", "JobRole")]
k_fold_cross_val(selected_features)
model_v2 <- rsf_model(selected_features)
plot_pec(selected_features, model_v2)
# Prediction
rsf_turnover_probability <- function (df, model) {
return(predict(model, df)$chf)
}
rsf_high_risk_indiv_idx <- function (df, model, limit = 100) {
df$HazardScore <- predict(model, df)$predicted
return(order(df$HazardScore, decreasing = TRUE)[1:limit])
}
for (i in 1:5) {
hr[, paste0("AttritionProb_Year", i)] <- rsf_turnover_probability(hr, model_v2)[, i+1]
}
hriidx <- rsf_high_risk_indiv_idx(hr, model_v2)
hr_emp_ids
hriidx
hridv <- hr[hriidx, c("AttritionProb_Year1", "AttritionProb_Year2", "AttritionProb_Year3",
"AttritionProb_Year4", "AttritionProb_Year5")]
plot(1, type = "n", xlim = c(1, ncol(hridv)), ylim = range(hridv), xlab = "Year", ylab = "Probability")
title("100 High-Risk Employee Turnoever Trajectory")
for (i in 1:nrow(hridv)) {
lines(1:ncol(hridv), hri[i, ], col = i, type = "l")
}
for (i in 1:nrow(hridv)) {
lines(1:ncol(hridv), hridv[i, ], col = i, type = "l")
}
legend("topright", legend = hr_emp_ids[hriidx], col = 1:nrow(hridv), lty = 1, title = "Employee Number")
hr_emp_ids[hriidx]
hriidx
hr_emp_ids
hriidx
hriidx[1:2]
hriidx[1:2] = c(15,712)
hriidx[1:2] == c(15,712)
hr_emp_ids[c(15,712)]
hr_emp_ids[1]
hr_emp_ids[2]
legend("topright", legend = hr_emp_ids[hriidx, ], col = 1:nrow(hridv), lty = 1, title = "Employee Number")
