#  if (length(unique_vals) <= 30) return(unique_vals)
#  return(c(unique_vals[1:30], "etc"))
#})
# Convert column data types
cat_cols <- c("BusinessTravel", "Department", "Gender", "EducationField", "JobRole", "MaritalStatus")
hr[cat_cols] <- lapply(hr[cat_cols], factor)
bool_cols <- c("Attrition", "Over18", "OverTime")
hr[bool_cols] <- lapply(hr[bool_cols], function (col) ifelse(col %in% c("Yes", "Y"), TRUE, FALSE))
# Filter irrelevant columns
cols <- names(hr)
cols <- cols[cols != "EmployeeNumber"]
single_value_cols <- names(hr)[sapply(hr, function (col) length(unique(col)) == 1)]
cols <- cols[!(cols %in% single_value_cols)]
# Adding columns
hr["NotWorkingYears"] <- hr["Age"] - hr["TotalWorkingYears"]
hr["YearsAtOtherCompanies"] <- hr["TotalWorkingYears"] - hr["YearsAtCompany"]
# Removing outliers
outlier_index <- function(df, col) {
vec <- df[[col]]
qnt <- quantile(vec, probs = c(0.25, 0.75))
iqr <- qnt[2] - qnt[1]
min <- qnt[1] - 3 * iqr
max <- qnt[2] + 3 * iqr
return(which(vec < min | vec > max))
}
hr_full_row <- hr
hr <- hr_full_row[-outlier_index(hr_full_row, "YearsAtCompany"), ]
library(caret)
library(survival)
library(randomForestSRC)
library(pec, warn.conflicts = FALSE)
library(ggplot2)
library(reshape2)
library(viridis)
# Models
coxph_model <- function (df) {
model <- coxph(data = df, formula = Surv(YearsAtCompany, Attrition) ~ ., method = "breslow", x = TRUE)
return(model)
}
rsf_model <- function (df) {
model <- rfsrc(Surv(YearsAtCompany, Attrition) ~ ., data = df, ntree = 100)
return(model)
}
# Cross-validation functions
train_test_generate <- function (df, proportion = 0.7) {
size <- round(proportion * nrow(df))
idx <- sample(1:size)
return(list("train" = df[idx, ], "test" = df[-idx, ]))
}
cross_val <- function (df, model_f, metric_f, k = 10) { # !!!! Test/train case may have 0 survival
random_index <- sample(1:nrow(df))
metrics <- integer(k)
for (fold in 1:k) {
prev_end <- round((fold-1)/k * nrow(df))
size <- round(fold/k * nrow(df)) - round((fold-1)/k * nrow(df))
idx <- random_index[(prev_end+1):size]
test <- df[idx, ]
train <- df[-idx, ]
model <- model_f(train)
metrics[[fold]] <- metric_f(test, model)
}
metrics_avg <- mean(na.omit(metrics))
return(metrics_avg[order(abs(metrics_avg), decreasing = TRUE)])
}
# Validation metrics
# 1. Feature rank
# ----- Cox score
coxph_score <- function (df, model) {
return(unlist(cindex(model, formula = Surv(YearsAtCompany, Attrition) ~ ., data = df)$AppCindex))
}
coxph_slope <- function (df, model) {
return(summary(model)$coefficients[, "coef"])
}
print_coxph_var_rank <- function (df) {
features <- names(df)[!(names(df) %in% c("Attrition", "YearsAtCompany"))]
scores <- sapply(features, function (col){
cross_val(df[c("Attrition", "YearsAtCompany", col)], coxph_model, coxph_score)
})
names(scores) <- features
print("Average univariate Cox score:")
print(scores[order(scores, decreasing = TRUE)])
}
# ----- Importance
rsf_importance <- function (df, model) {
importance <- predict(model, df, importance = TRUE)$importance
return(importance)
}
print_rsf_var_rank <- function (df) {
print("Average variable importance:")
print(cross_val(df, rsf_model, rsf_importance))
}
# 2. C-index
print_c_index <- function(df, model_f) {
print("Average concordance index:")
print(cross_val(df, model_f, coxph_score))
}
# 3. PEC
plot_pec <- function(df, model_f) {
suppressMessages(pred_error <- pec(model_f(df), data = df, formula = Surv(YearsAtCompany, Attrition) ~ .,
splitMethod = "cv10", cens.model = "marginal", reference = FALSE))
plot(pred_error, xlim = c(0, 10), ylim = c(0, 0.25)) # 0.25 is the worst case scenario (random model)
title("Prediction Error Curve")
}
# Assumption functions
check_proportional_hazard <- function(model) {
print(cox.zph(model))
}
plot_correlation <- function (df, limit = -1) {
# Only numerical (unless categories can be continuously extended)
num_cols <- sapply(df, is.numeric)
bool_cols <- sapply(df, is.logical)
df2 <- df[, num_cols | bool_cols]
# Only select the high-correlated columns
cor_matrix <- cor(df2)
high_cor_pairs <- which(cor_matrix >= limit & cor_matrix < 1, arr.ind = TRUE)
high_cor_cols <- colnames(df2)[high_cor_pairs[, 1]]
ggplot(data = melt(cor_matrix[high_cor_cols, high_cor_cols]), aes(x = Var1, y = Var2, fill = value)) +
geom_tile() + scale_fill_viridis() +
xlab("") + ylab("") + ggtitle("Correlation Map") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
plot.title = element_text(hjust = 0.5))
}
# Removing time-dependent variables, prop hazard violators
coxph_cols <- cols[!(cols %in% c("Age", "YearsWithCurrManager", "YearsInCurrentRole", "TotalWorkingYears", "YearsSinceLastPromotion",
"Department", "JobRole", "JobLevel", "MonthlyIncome", "NumCompaniesWorked", "NotWorkingYears"))]
# First iteration
hr1c <- hr[coxph_cols]
print_coxph_var_rank(hr1c)
# First iteration
hr1c <- hr[coxph_cols]
print_coxph_var_rank(hr1c)
x <- list (0, 0, 0)
x[[1]] <- list(10)
x
x <- list(c(0, 0), c(1, 0), c(2,0))
sum(x)
sum(unlist(x))
is.na(c(1,2))
is.na(list(x = 1, y =2))
numeric(0)
numeric(3)
nrow(c(1,1,1))
size(c(1,1,1))
dim(c(1,1,1))
rm(list = ls())
hr <- read.csv("hr_data.csv")
# No incorrect/problematic entries
#head(hr)
#nrow(hr[duplicated(hr), ])
#sum(is.na(hr))
#summary(hr)
#sapply(hr, function(x) {
#  unique_vals <- sort(unique(x))
#  if (length(unique_vals) <= 30) return(unique_vals)
#  return(c(unique_vals[1:30], "etc"))
#})
# Convert column data types
cat_cols <- c("BusinessTravel", "Department", "Gender", "EducationField", "JobRole", "MaritalStatus")
hr[cat_cols] <- lapply(hr[cat_cols], factor)
bool_cols <- c("Attrition", "Over18", "OverTime")
hr[bool_cols] <- lapply(hr[bool_cols], function (col) ifelse(col %in% c("Yes", "Y"), TRUE, FALSE))
# Filter irrelevant columns
cols <- names(hr)
cols <- cols[cols != "EmployeeNumber"]
single_value_cols <- names(hr)[sapply(hr, function (col) length(unique(col)) == 1)]
cols <- cols[!(cols %in% single_value_cols)]
# Adding columns
hr["NotWorkingYears"] <- hr["Age"] - hr["TotalWorkingYears"]
hr["YearsAtOtherCompanies"] <- hr["TotalWorkingYears"] - hr["YearsAtCompany"]
# Removing outliers
outlier_index <- function(df, col) {
vec <- df[[col]]
qnt <- quantile(vec, probs = c(0.25, 0.75))
iqr <- qnt[2] - qnt[1]
min <- qnt[1] - 3 * iqr
max <- qnt[2] + 3 * iqr
return(which(vec < min | vec > max))
}
hr_full_row <- hr
hr <- hr_full_row[-outlier_index(hr_full_row, "YearsAtCompany"), ]
library(caret)
library(survival)
library(randomForestSRC)
library(pec, warn.conflicts = FALSE)
library(ggplot2)
library(reshape2)
library(viridis)
# Models
coxph_model <- function (df) {
model <- coxph(data = df, formula = Surv(YearsAtCompany, Attrition) ~ ., method = "breslow", x = TRUE)
return(model)
}
rsf_model <- function (df) {
model <- rfsrc(Surv(YearsAtCompany, Attrition) ~ ., data = df, ntree = 100)
return(model)
}
# Cross-validation functions
train_test_generate <- function (df, proportion = 0.7) {
size <- round(proportion * nrow(df))
idx <- sample(1:size)
return(list("train" = df[idx, ], "test" = df[-idx, ]))
}
cross_val <- function (df, model_f, metric_f, k = 5) { # !!!! Test/train case may have 0 survival
random_index <- sample(1:nrow(df))
metrics <- integer(k)
for (fold in 1:k) {
prev_end <- round((fold-1)/k * nrow(df))
size <- round(fold/k * nrow(df)) - round((fold-1)/k * nrow(df))
idx <- random_index[(prev_end+1):size]
test <- df[idx, ]
train <- df[-idx, ]
model <- model_f(train)
metrics[[fold]] <- metric_f(test, model)
}
metrics_avg <- mean(na.omit(metrics))
return(metrics_avg[order(abs(metrics_avg), decreasing = TRUE)])
}
# Validation metrics
# 1. Feature rank
# ----- Cox score
coxph_score <- function (df, model) {
return(unlist(cindex(model, formula = Surv(YearsAtCompany, Attrition) ~ ., data = df)$AppCindex))
}
coxph_slope <- function (df, model) {
return(summary(model)$coefficients[, "coef"])
}
print_coxph_var_rank <- function (df) {
features <- names(df)[!(names(df) %in% c("Attrition", "YearsAtCompany"))]
scores <- sapply(features, function (col){
cross_val(df[c("Attrition", "YearsAtCompany", col)], coxph_model, coxph_score)
})
names(scores) <- features
print("Average univariate Cox score:")
print(scores[order(scores, decreasing = TRUE)])
}
# ----- Importance
rsf_importance <- function (df, model) {
importance <- predict(model, df, importance = TRUE)$importance
return(importance)
}
print_rsf_var_rank <- function (df) {
print("Average variable importance:")
print(cross_val(df, rsf_model, rsf_importance))
}
# 2. C-index
print_c_index <- function(df, model_f) {
print("Average concordance index:")
print(cross_val(df, model_f, coxph_score))
}
# 3. PEC
plot_pec <- function(df, model_f) {
suppressMessages(pred_error <- pec(model_f(df), data = df, formula = Surv(YearsAtCompany, Attrition) ~ .,
splitMethod = "cv10", cens.model = "marginal", reference = FALSE))
plot(pred_error, xlim = c(0, 10), ylim = c(0, 0.25)) # 0.25 is the worst case scenario (random model)
title("Prediction Error Curve")
}
# Assumption functions
check_proportional_hazard <- function(model) {
print(cox.zph(model))
}
plot_correlation <- function (df, limit = -1) {
# Only numerical (unless categories can be continuously extended)
num_cols <- sapply(df, is.numeric)
bool_cols <- sapply(df, is.logical)
df2 <- df[, num_cols | bool_cols]
# Only select the high-correlated columns
cor_matrix <- cor(df2)
high_cor_pairs <- which(cor_matrix >= limit & cor_matrix < 1, arr.ind = TRUE)
high_cor_cols <- colnames(df2)[high_cor_pairs[, 1]]
ggplot(data = melt(cor_matrix[high_cor_cols, high_cor_cols]), aes(x = Var1, y = Var2, fill = value)) +
geom_tile() + scale_fill_viridis() +
xlab("") + ylab("") + ggtitle("Correlation Map") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
plot.title = element_text(hjust = 0.5))
}
# Removing time-dependent variables, prop hazard violators
coxph_cols <- cols[!(cols %in% c("Age", "YearsWithCurrManager", "YearsInCurrentRole", "TotalWorkingYears", "YearsSinceLastPromotion",
"Department", "JobRole", "JobLevel", "MonthlyIncome", "NumCompaniesWorked", "NotWorkingYears"))]
# First iteration
hr1c <- hr[coxph_cols]
print_coxph_var_rank(hr1c)
# Final iteration
rsf_cols <- c("Attrition", "YearsAtCompany", "JobLevel", "OverTime", "StockOptionLevel",
"JobRole", "EnvironmentSatisfaction", "NotWorkingYears")
coxph_cols <- c("Attrition", "YearsAtCompany", "OverTime", "JobInvolvement", "DistanceFromHome",
"JobSatisfaction", "BusinessTravel", "EnvironmentSatisfaction", "MaritalStatus",
"Gender")
rsf_final_model <- rsf_model(hr[rsf_cols])
coxph_final_model <- coxph_model(hr[coxph_cols])
cols <- c("Attrition", "YearsAtCompany", "MonthlyIncome", "OverTime", "Age",
"JobRole", "NumCompaniesWorkedPerYear", "StockOptionLevel")
# Prediction
hr["HazardRatio_CoxPH"] <- predict(coxph_final_model, hr, type = "risk")
# coxph_risk <- exp(predict(coxph_final_model, hr, type = "lp")) %*% t(basehaz(coxph_final_model)["hazard"])
years = 5
rsf_risk <- predict(rsf_final_model, hr)$chf[, 1:(years+1)] # matrix
rsf_survival_probs <- predict(rsf_final_model, hr)$survival[, 1:(years+1)]
hr["Hazard_RSF_Current"] <- rsf_risk[, 1]
hzrsf_cols <- sapply(0:years, function(i) {paste0("Hazard_RSF_", i)})
hr[hzrsf_cols] <- rsf_risk[, 1 + (0:years)]
preview_cols <- c("EmployeeNumber", coxph_cols, rsf_cols, "HazardRatio_CoxPH", hzrsf_cols)
# Table sorted by Cox Hazard Ratio
cutoff = 50
sorted <- function (df, key_col) {
df <- df[df["Attrition"] == FALSE, ]
return(row.names(df)[order(df[, key_col], decreasing = TRUE)][1:cutoff])
}
hr_sorted_coxph <- hr[sorted(hr, "HazardRatio_CoxPH"), ]
head(hr_sorted_coxph[, preview_cols])
#hridv <- hr[hr_sorted_coxph(hr, "Hazard_RSF"), preview_cols]
#plot(1, type = "n", xlim = c(0, 5), ylim = c(0, 1), xlab = "Year", ylab = "Probability")
#title("High-Risk Employee Turnoever Trajectory")
#for (i in 1:cutoff) {
#  lines(0:years, hridv[i, ap_cols], col = i, type = "l")
#}
#legend("topleft", legend = hridv[, "EmployeeNumber"], col = 1:nrow(hridv), lty = 1, title = "Employee Number")
# Plotly implementation
suppressMessages(library(plotly))
group <- "EmployeeNumber"
hr_sorted_rsf <- hr[sorted(hr, "Hazard_RSF_Current"), ]
# Adding RSH trajectory risks
fig <- plot_ly()
for (rank in 1:cutoff) {
employee_row_num <- as.numeric(rownames(hr_sorted_rsf)[rank])
employee_row <- hr_sorted_rsf[rank, ]
x <- 0:(ncol(rsf_risk)-1)
y <- rsf_risk[employee_row_num, ]
fig <- fig %>% add_trace(x = x,
y = y,
name = employee_row["EmployeeNumber"],
type = "scatter", mode = "lines+markers", # every time you put type, it assign DOMNum = 0
marker = list(size = 4),
line = list(shape = "spline", width = 1),
hovertemplate = paste0("<i>#", rank, ": Employee ", employee_row["EmployeeNumber"], "</i>",
"\nYear: ", x,
"\nRisk score: ", y),
legendgroup = employee_row["EmployeeNumber"],
showlegend = TRUE
)
}
# CoxPH
fig <- fig %>% add_trace(data = hr_sorted_coxph,
y = ~HazardRatio_CoxPH,
type = "bar",
marker = list(color = ~YearsAtCompany),
hovertemplate = paste0("Employee ", hr_sorted_coxph$EmployeeNumber,
"\nHazard ratio: ", hr_sorted_coxph$HazardRatio_CoxPH),
visible = FALSE, showlegend = FALSE)
# --- Decorators
# Including the baseline
avg_cum_hazard <- -log(1-mean(hr[, "Attrition"]))
baseline <- list(
type = "line", x0 = 0, x1 = 5, y0 = avg_cum_hazard, y1 = avg_cum_hazard,
line = list(dash = "dash", width = 4, color = "#82A0D8")
)
fig <- fig %>% layout(
shapes = list(baseline)
) %>% add_text(
showlegend = FALSE, x = 0.3, y = 0.22, text = "Average hazard",
textfont = list(family = "sans serif", size = 10)
)
# Helper function to group RSF metrics based on variables
library(RColorBrewer)
unique_index <- function(x) {
unique_vals <- unique(x)
first_occur <- integer(length(unique_vals))
for (i in 1:length(unique_vals)) {
first_occur[i] <- which(x == unique_vals[i])[1]
}
return(first_occur)
}
create_buttons <- function(vars) {
lapply(vars, function(var) {
color_palletes <- brewer.pal(12, "Set3")
var_factors <- as.numeric(factor(hr_sorted_rsf[[var]]))
button <- list(
method = "restyle",
label = var,
args = list(list( # Some elements are just "double-list". This changes style to every DOM elements
line.color = color_palletes[var_factors],
marker.color = color_palletes[var_factors],
legendgroup = hr_sorted_rsf[[var]],
showlegend = 1:cutoff %in% unique_index(var_factors),
name = as.character(hr_sorted_rsf[[var]])
), 1:cutoff - 1) # The DOMNum it applies to
)
return(button)
})
}
# --- Setting layout
coxph_layout = list(
title = "High-Risk Employees, according to Hazard Ratio",
shapes = list(),
xaxis = list(title = "Rank"),
yaxis = list(title = "Hazard Ratio")
)
rsf_layout = list(
title = "High-Risk Employees: RSF's Accumulated Risk Trajectory",
shapes = list(baseline),
xaxis = list(title = "Year", range = c(0, 5), zerolinecolor = '#ffff'),
yaxis = list(title = "Accummulated Risk until Year _", range = c(0, 1.5), zerolinecolor = '#ffff')
)
fig <- fig %>% layout(unlist(rsf_layout)) %>% layout(
title = "High-Risk Employees: RSF's Accumulated Risk Trajectory",
shapes = list(baseline),
xaxis = list(title = "Year", range = c(0, 5), zerolinecolor = '#ffff'),
yaxis = list(title = "Accummulated Risk until Year _", range = c(0, 1.5), zerolinecolor = '#ffff'),
plot_bgcolor = '#e5ecf6',
updatemenus = list(
list(
x = -0.1, y = 0.9, yref = "paper",
showactive = TRUE,
buttons = list(
list(
label = "Random Survival Forest",
method = "update",
args = list(list(visible = c(rep(TRUE, cutoff), FALSE, TRUE)), rsf_layout, 1:(cutoff+2) - 1)
),
list(
label = "Cox Proportional",
method = "update",
args = list(list(visible = c(rep(FALSE, cutoff), TRUE, FALSE)), coxph_layout, 1:(cutoff+2) - 1)
)
)
), list(
x = -0.1, y = 0.6, yref = "paper",
showactive = TRUE,
buttons = create_buttons(c("EmployeeNumber", "BusinessTravel", "EnvironmentSatisfaction", "Gender",
"JobLevel", "JobRole", "JobSatisfaction", "MaritalStatus", "NumCompaniesWorked",
"OverTime", "StockOptionLevel"))
)
), annotations = list(
list(
x = -0.35, y = 1, xref = "paper", yref = "paper",
text = "Method", align = "left", showarrow = FALSE
), list(
x = -0.35, y = 0.7, xref = "paper", yref = "paper",
text = "Based on", align = "left", showarrow = FALSE, visible = TRUE
)
)
)
fig
x <- c(1,2)
x <- c(0,0)
names(x) <- c("a", "b")
x + y
x <- c(0,0)
y <- c(0,0)
names(x) <- c("a", "b")
x
y
x+y
y
x+y[1:2]
cindex(rsf_model(hr1c), formula = Surv(YearsAtCompany, Attrition) ~ ., data = hr1c)
cindex(rsf_model(hr1c), formula = Surv(YearsAtCompany, Attrition) ~ ., data = hr1c)
cindex(rsf_model(hr1c), formula = Surv(YearsAtCompany, Attrition) ~ ., data = hr1c)$AppCindex
unlist(cindex(rsf_model(hr1c), formula = Surv(YearsAtCompany, Attrition) ~ ., data = hr1c)$AppCindex)
unlist(cindex(rsf_model(hr1c), formula = Surv(YearsAtCompany, Attrition) ~ ., data = hr1c)$Pairs) == 0
if(unlist(cindex(rsf_model(hr1c), formula = Surv(YearsAtCompany, Attrition) ~ ., data = hr1c)$Pairs) == 0) print("AAA")
if(unlist(cindex(rsf_model(hr1c), formula = Surv(YearsAtCompany, Attrition) ~ ., data = hr1c)$Pairs) != 0) print("AAA")
(predict(rsf_model(hr1c), hr1c, importance = TRUE)$importance)
x <- (predict(rsf_model(hr1c), hr1c, importance = TRUE)$importance)
str(x)
is.vector(x)
is.vector(unlist(cindex(rsf_model(hr1c), formula = Surv(YearsAtCompany, Attrition) ~ ., data = hr1c)$Pairs))
y <- is.vector(unlist(cindex(rsf_model(hr1c), formula = Surv(YearsAtCompany, Attrition) ~ ., data = hr1c)$AppCindex
y
y <- unlist(cindex(rsf_model(hr1c), formula = Surv(YearsAtCompany, Attrition) ~ ., data = hr1c)$AppCindex)
y
numeric(length(y))
length(y)
numeric(length(y)) + y
is.vector(0)
is.vector(1)
numeric(1)
numeric(0)
str(predict(rsf_model(hr1c), hr1c, importance = TRUE)$importance)
length(predict(rsf_model(hr1c), hr1c, importance = TRUE)$importance)
y <- predict(rsf_model(hr1c), hr1c, importance = TRUE)$importance
summary(coxph_model(hr1c))$coefficients
x <- c(1,2,2,4,5)
names(x) <- c(4,5,6,7,8)
x[[1]]
x[[2]]
x[[3]]
x = c(c(1,2), c(3,4))
c
x
x = matrix(c(c(1,2), c(3,4)))
x
x = matrix(c(1,2), c(3,4))
x = matrix(list(c(1,2), c(3,4)))
x
x = matrix(list(list(1,2), list(3,4)))
x
rsf_risk <- predict(rsf_final_model, hr)$chf[, 1:(years+1)]
DATA <- read.csv("hr_data.csv")
SIZE <- round(0.1*nrow(DATA))
SIZE
RAND <- sample(1:nrow(DATA))
RAND
RAND[1:round(0.1*nrow(DATA))]
DATA[-RAND[1:round(0.1*nrow(DATA))], ]
DATA
data.frame(DATA[-RAND[1:round(0.1*nrow(DATA))], ])
x <- DATA[-RAND[1:round(0.1*nrow(DATA))], ]
names(x) <- 1:nrow(x)
names(x
)
row.names(x) <- 1:nrow(x)
x
